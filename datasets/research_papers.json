[
    {
        "title": "L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling",
        "authors": "Zhuo Chen, \n      \n      Oriol Mayn\u00e9 i Comas, \n      \n      Zhuotao Jin, \n      \n      Di Luo, \n      \n      Marin Solja\u010di\u0107",
        "summary": "We rigorously establish a bipartite mutual information scaling law in natural language that governs long-range dependencies. This scaling law, which we show is distinct from and scales independently of the conventional two-point mutual information, is the key to understanding long-context language modeling. Using this scaling law, we formulate the Long-context Language Modeling (L$^2$M) condition, which relates a model's capacity for effective long context length modeling to the scaling of its latent state size for storing past information. Our results are validated through experiments on both transformers and state space models. This work establishes a theoretical foundation that guides the development of large language models toward longer context lengths.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04725"
    },
    {
        "title": "Shifting Long-Context LLMs Research from Input to Output",
        "authors": "Yuhao Wu, \n      \n      Yushi Bai, \n      \n      Zhiqing Hu, \n      \n      Shangqing Tu, \n      \n      Ming Shan Hee, \n      \n      Juanzi Li, \n      \n      Roy Ka-Wei Lee",
        "summary": "Recent advancements in long-context Large Language Models (LLMs) have primarily concentrated on processing extended input contexts, resulting in significant strides in long-context comprehension. However, the equally critical aspect of generating long-form outputs has received comparatively less attention. This paper advocates for a paradigm shift in NLP research toward addressing the challenges of long-output generation. Tasks such as novel writing, long-term planning, and complex reasoning require models to understand extensive contexts and produce coherent, contextually rich, and logically consistent extended text. These demands highlight a critical gap in current LLM capabilities. We underscore the importance of this under-explored domain and call for focused efforts to develop foundational LLMs tailored for generating high-quality, long-form outputs, which hold immense potential for real-world applications.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04723"
    },
    {
        "title": "Enough Coin Flips Can Make LLMs Act Bayesian",
        "authors": "Ritwik Gupta, \n      \n      Rodolfo Corona, \n      \n      Jiaxin Ge, \n      \n      Eric Wang, \n      \n      Dan Klein, \n      \n      Trevor Darrell, \n      \n      David M. Chan",
        "summary": "Large language models (LLMs) exhibit the ability to generalize given few-shot examples in their input prompt, an emergent capability known as in-context learning (ICL). We investigate whether LLMs utilize ICL to perform structured reasoning in ways that are consistent with a Bayesian framework or rely on pattern matching. Using a controlled setting of biased coin flips, we find that: (1) LLMs often possess biased priors, causing initial divergence in zero-shot settings, (2) in-context evidence outweighs explicit bias instructions, (3) LLMs broadly follow Bayesian posterior updates, with deviations primarily due to miscalibrated priors rather than flawed updates, and (4) attention magnitude has negligible effect on Bayesian inference. With sufficient demonstrations of biased coin flips via ICL, LLMs update their priors in a Bayesian manner.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04722"
    },
    {
        "title": "Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining",
        "authors": "Houyi Li, \n      \n      Wenzheng Zheng, \n      \n      Jingcheng Hu, \n      \n      Qiufeng Wang, \n      \n      Hanshan Zhang, \n      \n      Zili Wang, \n      \n      Yangshijie Xu, \n      \n      Shuigeng Zhou, \n      \n      Xiangyu Zhang, \n      \n      Daxin Jiang",
        "summary": "The impressive capabilities of Large Language Models (LLMs) across diverse tasks are now well-established, yet their effective deployment necessitates careful hyperparameter optimization. Through extensive empirical studies involving grid searches across diverse configurations, we discover universal scaling laws governing these hyperparameters: optimal learning rate follows a power-law relationship with both model parameters and data sizes, while optimal batch size scales primarily with data sizes. Our analysis reveals a convex optimization landscape for hyperparameters under fixed models and data size conditions. This convexity implies an optimal hyperparameter plateau. We contribute a universal, plug-and-play optimal hyperparameter tool for the community. Its estimated values on the test set are merely 0.07\\% away from the globally optimal LLM performance found via an exhaustive search. These laws demonstrate remarkable robustness across variations in model sparsity, training data distribution, and model shape. To our best known, this is the first work that unifies different model shapes and structures, such as Mixture-of-Experts models and dense transformers, as well as establishes optimal hyperparameter scaling laws across diverse data distributions. This exhaustive optimization process demands substantial computational resources, utilizing nearly one million NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and hyperparameters from scratch and consuming approximately 100 trillion tokens in total. To facilitate reproducibility and further research, we will progressively release all loss measurements and model checkpoints through our designated repository https://step-law.github.io/\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04715"
    },
    {
        "title": "Scaling Rich Style-Prompted Text-to-Speech Datasets",
        "authors": "Anuj Diwan, \n      \n      Zhisheng Zheng, \n      \n      David Harwath, \n      \n      Eunsol Choi",
        "summary": "We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale dataset that annotates speech utterances with rich style captions. While rich abstract tags (e.g. guttural, nasal, pained) have been explored in small-scale human-annotated datasets, existing large-scale datasets only cover basic tags (e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech embedders, classifiers and an audio language model to automatically scale rich tag annotations for the first time. ParaSpeechCaps covers a total of 59 style tags, including both speaker-level intrinsic tags and utterance-level situational tags. It consists of 342 hours of human-labelled data (PSC-Base) and 2427 hours of automatically annotated data (PSC-Scaled). We finetune Parler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and achieve improved style consistency (+7.9% Consistency MOS) and speech quality (+15.5% Naturalness MOS) over the best performing baseline that combines existing rich style tag datasets. We ablate several of our dataset design choices to lay the foundation for future work in this space. Our dataset, models and code are released at https://github.com/ajd12342/paraspeechcaps .\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04713"
    },
    {
        "title": "Self-Supervised Models for Phoneme Recognition: Applications in Children's Speech for Reading Learning",
        "authors": "Lucas Block Medin, \n      \n      Thomas Pellegrini, \n      \n      Lucile Gelin",
        "summary": "Child speech recognition is still an underdeveloped area of research due to the lack of data (especially on non-English languages) and the specific difficulties of this task. Having explored various architectures for child speech recognition in previous work, in this article we tackle recent self-supervised models. We first compare wav2vec 2.0, HuBERT and WavLM models adapted to phoneme recognition in French child speech, and continue our experiments with the best of them, WavLM base+. We then further adapt it by unfreezing its transformer blocks during fine-tuning on child speech, which greatly improves its performance and makes it significantly outperform our base model, a Transformer+CTC. Finally, we study in detail the behaviour of these two models under the real conditions of our application, and show that WavLM base+ is more robust to various reading tasks and noise levels. Index Terms: speech recognition, child speech, self-supervised learning\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04710"
    },
    {
        "title": "Universality of Layer-Level Entropy-Weighted Quantization Beyond Model Architecture and Size",
        "authors": "Alireza Behtash, \n      \n      Marijan Fofonjka, \n      \n      Ethan Baird, \n      \n      Tyler Mauer, \n      \n      Hossein Moghimifam, \n      \n      David Stout, \n      \n      Joel Dennison",
        "summary": "We present a novel approach to selective model quantization that transcends the limitations of architecture-specific and size-dependent compression methods for Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By analyzing the entropy distribution across transformer blocks, EWQ determines which blocks can be safely quantized without causing significant performance degradation, independent of model architecture or size. Our method outperforms uniform quantization approaches, maintaining Massive Multitask Language Understanding (MMLU) accuracy scores within 0.5% of unquantized models while reducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ across multiple architectures-from 1.6B to 70B parameters-showcasing consistent improvements in the quality-compression trade-off regardless of model scale or architectural design. A surprising finding of EWQ is its ability to reduce perplexity compared to unquantized models, suggesting the presence of beneficial regularization through selective precision reduction. This improvement holds across different model families, indicating a fundamental relationship between layer-level entropy and optimal precision requirements. Additionally, we introduce FastEWQ, a rapid method for entropy distribution analysis that eliminates the need for loading model weights. This technique leverages universal characteristics of entropy distribution that persist across various architectures and scales, enabling near-instantaneous quantization decisions while maintaining 80% classification accuracy with full entropy analysis. Our results demonstrate that effective quantization strategies can be developed independently of specific architectural choices or model sizes, opening new possibilities for efficient LLM deployment.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04704"
    },
    {
        "title": "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning",
        "authors": "Pranjal Aggarwal, \n      \n      Sean Welleck",
        "summary": "Reasoning language models have shown an uncanny ability to improve performance at test-time by ``thinking longer''-that is, by generating longer chain-of-thought sequences and hence using more compute. However, the length of their chain-of-thought reasoning is not controllable, making it impossible to allocate test-time compute to achieve a desired level of performance. We introduce Length Controlled Policy Optimization (LCPO), a simple reinforcement learning method that optimizes for accuracy and adherence to user-specified length constraints. We use LCPO to train L1, a reasoning language model that produces outputs satisfying a length constraint given in its prompt. L1's length control allows for smoothly trading off computational cost and accuracy on a wide range of tasks, and outperforms the state-of-the-art S1 method for length control. Furthermore, we uncover an unexpected short chain-of-thought capability in models trained with LCPO. For instance, our 1.5B L1 model surpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise control over reasoning length, allowing for fine-grained allocation of test-time compute and accuracy. We release code and models at https://www.cmu-l3.github.io/l1\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04697"
    },
    {
        "title": "Assessing Student Adoption of Generative Artificial Intelligence across Engineering Education from 2023 to 2024",
        "authors": "Jesan Ahammed Ovi, \n      \n      Gabe Fierro, \n      \n      C. Estelle Smith",
        "summary": "Generative Artificial Intelligence (GenAI) tools and models have the potential to re-shape educational needs, norms, practices, and policies in all sectors of engineering education. Empirical data, rather than anecdata and assumptions, on how engineering students have adopted GenAI is essential to developing a foundational understanding of students' GenAI-related behaviors and needs during academic training. This data will also help formulate effective responses to GenAI by both academic institutions and industrial employers. We collected two representative survey samples at the Colorado School of Mines, a small engineering-focused R-1 university in the USA, in May 2023 ($n_1=601$) and September 2024 ($n_2=862$) to address research questions related to (RQ1) how GenAI has been adopted by engineering students, including motivational and demographic factors contributing to GenAI use, (RQ2) students' ethical concerns about GenAI, and (RQ3) students' perceived benefits v.s. harms for themselves, science, and society. Analysis revealed a statistically significant rise in GenAI adoption rates from 2023 to 2024. Students predominantly leverage GenAI tools to deepen understanding, enhance work quality, and stay informed about emerging technologies. Although most students assess their own usage of GenAI as ethical and beneficial, they nonetheless expressed significant concerns regarding GenAI and its impacts on society. We collected student estimates of ``P(doom)'' and discovered a bimodal distribution. Thus, we show that the student body at Mines is polarized with respect to future impacts of GenAI on the engineering workforce and society, despite being increasingly willing to explore GenAI over time. We discuss implications of these findings for future research and for integrating GenAI in engineering education.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04696"
    },
    {
        "title": "Matrix Factorization for Inferring Associations and Missing Links",
        "authors": "Ryan Barron, \n      \n      Maksim E. Eren, \n      \n      Duc P. Truong, \n      \n      Cynthia Matuszek, \n      \n      James Wendelberger, \n      \n      Mary F. Dorn, \n      \n      Boian Alexandrov",
        "summary": "Missing link prediction is a method for network analysis, with applications in recommender systems, biology, social sciences, cybersecurity, information retrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs. Missing link prediction identifies unseen but potentially existing connections in a network by analyzing the observed patterns and relationships. In proliferation detection, this supports efforts to identify and characterize attempts by state and non-state actors to acquire nuclear weapons or associated technology - a notoriously challenging but vital mission for global security. Dimensionality reduction techniques like Non-Negative Matrix Factorization (NMF) and Logistic Matrix Factorization (LMF) are effective but require selection of the matrix rank parameter, that is, of the number of hidden features, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk), Boolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along with ensemble variants incorporating logistic factorization, for link prediction. Our methods integrate automatic model determination for rank estimation by evaluating stability and accuracy using a modified bootstrap methodology and uncertainty quantification (UQ), assessing prediction reliability under random perturbations. We incorporate Otsu threshold selection and k-means clustering for Boolean matrix factorization, comparing them to coordinate descent-based Boolean thresholding. Our experiments highlight the impact of rank k selection, evaluate model performance under varying test-set sizes, and demonstrate the benefits of UQ for reliable predictions using abstention. We validate our methods on three synthetic datasets (Boolean and uniformly distributed) and benchmark them against LMF and symmetric LMF (symLMF) on five real-world protein-protein interaction networks, showcasing an improved prediction performance.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04680"
    },
    {
        "title": "Multi-Agent Inverse Q-Learning from Demonstrations",
        "authors": "Nathaniel Haynam, \n      \n      Adam Khoja, \n      \n      Dhruv Kumar, \n      \n      Vivek Myers, \n      \n      Erdem B\u0131y\u0131k",
        "summary": "When reward functions are hand-designed, deep reinforcement learning algorithms often suffer from reward misspecification, causing them to learn suboptimal policies in terms of the intended task objectives. In the single-agent case, inverse reinforcement learning (IRL) techniques attempt to address this issue by inferring the reward function from expert demonstrations. However, in multi-agent problems, misalignment between the learned and true objectives is exacerbated due to increased environment non-stationarity and variance that scales with multiple agents. As such, in multi-agent general-sum games, multi-agent IRL algorithms have difficulty balancing cooperative and competitive objectives. To address these issues, we propose Multi-Agent Marginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient framework for multi-agent IRL. For each agent, MAMQL learns a critic marginalized over the other agents' policies, allowing for a well-motivated use of Boltzmann policies in the multi-agent context. We identify a connection between optimal marginalized critics and single-agent soft-Q IRL, allowing us to apply a direct, simple optimization criterion from the single-agent domain. Across our experiments on three different simulated domains, MAMQL significantly outperforms previous multi-agent methods in average reward, sample efficiency, and reward recovery by often more than 2-5x. We make our code available at https://sites.google.com/view/mamql .\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04679"
    },
    {
        "title": "Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment",
        "authors": "Wen Yang, \n      \n      Junhong Wu, \n      \n      Chen Wang, \n      \n      Chengqing Zong, \n      \n      Jiajun Zhang",
        "summary": "Direct Preference Optimization (DPO) has become a prominent method for aligning Large Language Models (LLMs) with human preferences. While DPO has enabled significant progress in aligning English LLMs, multilingual preference alignment is hampered by data scarcity. To address this, we propose a novel approach that $\\textit{captures}$ learned preferences from well-aligned English models by implicit rewards and $\\textit{transfers}$ them to other languages through iterative training. Specifically, we derive an implicit reward model from the logits of an English DPO-aligned model and its corresponding reference model. This reward model is then leveraged to annotate preference relations in cross-lingual instruction-following pairs, using English instructions to evaluate multilingual responses. The annotated data is subsequently used for multilingual DPO fine-tuning, facilitating preference knowledge transfer from English to other languages. Fine-tuning Llama3 for two iterations resulted in a 12.72% average improvement in Win Rate and a 5.97% increase in Length Control Win Rate across all training languages on the X-AlpacaEval leaderboard. Our findings demonstrate that leveraging existing English-aligned models can enable efficient and effective multilingual preference alignment, significantly reducing the need for extensive multilingual preference data. The code is available at https://github.com/ZNLP/Implicit-Cross-Lingual-Rewarding\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04647"
    },
    {
        "title": "Ultra-Low-Latency Edge Intelligent Sensing: A Source-Channel Tradeoff and Its Application to Coding Rate Adaptation",
        "authors": "Qunsong Zeng, \n      \n      Jianhao Huang, \n      \n      Zhanwei Wang, \n      \n      Kaibin Huang, \n      \n      Kin K. Leung",
        "summary": "The forthcoming sixth-generation (6G) mobile network is set to merge edge artificial intelligence (AI) and integrated sensing and communication (ISAC) extensively, giving rise to the new paradigm of edge intelligent sensing (EI-Sense). This paradigm leverages ubiquitous edge devices for environmental sensing and deploys AI algorithms at edge servers to interpret the observations via remote inference on wirelessly uploaded features. A significant challenge arises in designing EI-Sense systems for 6G mission-critical applications, which demand high performance under stringent latency constraints. To tackle this challenge, we focus on the end-to-end (E2E) performance of EI-Sense and characterize a source-channel tradeoff that balances source distortion and channel reliability. In this work, we establish a theoretical foundation for the source-channel tradeoff by quantifying the effects of source coding on feature discriminant gains and channel reliability on packet loss. Building on this foundation, we design the coding rate control by optimizing the tradeoff to minimize the E2E sensing error probability, leading to a low-complexity algorithm for ultra-low-latency EI-Sense. Finally, we validate our theoretical analysis and proposed coding rate control algorithm through extensive experiments on both synthetic and real datasets, demonstrating the sensing performance gain of our approach with respect to traditional reliability-centric methods.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04645"
    },
    {
        "title": "Simulating the Real World: A Unified Survey of Multimodal Generative Models",
        "authors": "Yuqi Hu, \n      \n      Longguang Wang, \n      \n      Xian Liu, \n      \n      Ling-Hao Chen, \n      \n      Yuwei Guo, \n      \n      Yukai Shi, \n      \n      Ce Liu, \n      \n      Anyi Rao, \n      \n      Zeyu Wang, \n      \n      Hui Xiong",
        "summary": "Understanding and replicating the real world is a critical challenge in Artificial General Intelligence (AGI) research. To achieve this, many existing approaches, such as world models, aim to capture the fundamental principles governing the physical world, enabling more accurate simulations and meaningful interactions. However, current methods often treat different modalities, including 2D (images), videos, 3D, and 4D representations, as independent domains, overlooking their interdependencies. Additionally, these methods typically focus on isolated dimensions of reality without systematically integrating their connections. In this survey, we present a unified survey for multimodal generative models that investigate the progression of data dimensionality in real-world simulation. Specifically, this survey starts from 2D generation (appearance), then moves to video (appearance+dynamics) and 3D generation (appearance+geometry), and finally culminates in 4D generation that integrate all dimensions. To the best of our knowledge, this is the first attempt to systematically unify the study of 2D, video, 3D and 4D generation within a single framework. To guide future research, we provide a comprehensive review of datasets, evaluation metrics and future directions, and fostering insights for newcomers. This survey serves as a bridge to advance the study of multimodal generative models and real-world simulation within a unified framework.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04641"
    },
    {
        "title": "Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking",
        "authors": "Yijie Xu, \n      \n      Aiwei Liu, \n      \n      Xuming Hu, \n      \n      Lijie Wen, \n      \n      Hui Xiong",
        "summary": "As open-source large language models (LLMs) like Llama3 become more capable, it is crucial to develop watermarking techniques to detect their potential misuse. Existing watermarking methods either add watermarks during LLM inference, which is unsuitable for open-source LLMs, or primarily target classification LLMs rather than recent generative LLMs. Adapting these watermarks to open-source LLMs for misuse detection remains an open challenge. This work defines two misuse scenarios for open-source LLMs: intellectual property (IP) violation and LLM Usage Violation. Then, we explore the application of inference-time watermark distillation and backdoor watermarking in these contexts. We propose comprehensive evaluation methods to assess the impact of various real-world further fine-tuning scenarios on watermarks and the effect of these watermarks on LLM performance. Our experiments reveal that backdoor watermarking could effectively detect IP Violation, while inference-time watermark distillation is applicable in both scenarios but less robust to further fine-tuning and has a more significant impact on LLM performance compared to backdoor watermarking. Exploring more advanced watermarking methods for open-source LLMs to detect their misuse should be an important future direction.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04636"
    },
    {
        "title": "IDInit: A Universal and Stable Initialization Method for Neural Network Training",
        "authors": "Yu Pan, \n      \n      Chaozheng Wang, \n      \n      Zekai Wu, \n      \n      Qifan Wang, \n      \n      Min Zhang, \n      \n      Zenglin Xu",
        "summary": "Deep neural networks have achieved remarkable accomplishments in practice. The success of these networks hinges on effective initialization methods, which are vital for ensuring stable and rapid convergence during training. Recently, initialization methods that maintain identity transition within layers have shown good efficiency in network training. These techniques (e.g., Fixup) set specific weights to zero to achieve identity control. However, settings of remaining weight (e.g., Fixup uses random values to initialize non-zero weights) will affect the inductive bias that is achieved only by a zero weight, which may be harmful to training. Addressing this concern, we introduce fully identical initialization (IDInit), a novel method that preserves identity in both the main and sub-stem layers of residual networks. IDInit employs a padded identity-like matrix to overcome rank constraints in non-square weight matrices. Furthermore, we show the convergence problem of an identity matrix can be solved by stochastic gradient descent. Additionally, we enhance the universality of IDInit by processing higher-order weights and addressing dead neuron problems. IDInit is a straightforward yet effective initialization method, with improved convergence, stability, and performance across various settings, including large-scale datasets and deep models.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04626"
    },
    {
        "title": "The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation",
        "authors": "Aoxiong Yin, \n      \n      Kai Shen, \n      \n      Yichong Leng, \n      \n      Xu Tan, \n      \n      Xinyu Zhou, \n      \n      Juncheng Li, \n      \n      Siliang Tang",
        "summary": "Recent advancements in text-to-video (T2V) generation have been driven by two competing paradigms: autoregressive language models and diffusion models. However, each paradigm has intrinsic limitations: language models struggle with visual quality and error accumulation, while diffusion models lack semantic understanding and causal modeling. In this work, we propose LanDiff, a hybrid framework that synergizes the strengths of both paradigms through coarse-to-fine generation. Our architecture introduces three key innovations: (1) a semantic tokenizer that compresses 3D visual features into compact 1D discrete representations through efficient semantic compression, achieving a $\\sim$14,000$\\times$ compression ratio; (2) a language model that generates semantic tokens with high-level semantic relationships; (3) a streaming diffusion model that refines coarse semantics into high-fidelity videos. Experiments show that LanDiff, a 5B model, achieves a score of 85.43 on the VBench T2V benchmark, surpassing the state-of-the-art open-source models Hunyuan Video (13B) and other commercial models such as Sora, Keling, and Hailuo. Furthermore, our model also achieves state-of-the-art performance in long video generation, surpassing other open-source models in this field. Our demo can be viewed at https://landiff.github.io/.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04606"
    },
    {
        "title": "HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization",
        "authors": "Zhijian Zhuo, \n      \n      Yutao Zeng, \n      \n      Ya Wang, \n      \n      Sijun Zhang, \n      \n      Jian Yang, \n      \n      Xiaoqing Li, \n      \n      Xun Zhou, \n      \n      Jinwen Ma",
        "summary": "Transformers have become the de facto architecture for a wide range of machine learning tasks, particularly in large language models (LLMs). Despite their remarkable performance, challenges remain in training deep transformer networks, especially regarding the location of layer normalization. While Pre-Norm structures facilitate easier training due to their more prominent identity path, they often yield suboptimal performance compared to Post-Norm. In this paper, we propose $\\textbf{HybridNorm}$, a straightforward yet effective hybrid normalization strategy that integrates the advantages of both Pre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV normalization within the attention mechanism and Post-Norm in the feed-forward network (FFN) of each transformer block. This design not only stabilizes training but also enhances performance, particularly in the context of LLMs. Comprehensive experiments in both dense and sparse architectures show that HybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches, achieving state-of-the-art results across various benchmarks. These findings highlight the potential of HybridNorm as a more stable and effective technique for improving the training and performance of deep transformer models. %Code will be made publicly available. Code is available at https://github.com/BryceZhuo/HybridNorm.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04598"
    },
    {
        "title": "The Next Frontier of LLM Applications: Open Ecosystems and Hardware Synergy",
        "authors": "Xinyi Hou, \n      \n      Yanjie Zhao, \n      \n      Haoyu Wang",
        "summary": "Large Language Model (LLM) applications, including LLM app stores and autonomous agents, are shaping the future of AI ecosystems. However, platform silos, fragmented hardware integration, and the absence of standardized interfaces limit scalability, interoperability, and resource efficiency. While LLM app stores democratize AI, their closed ecosystems restrict modular AI reuse and cross-platform portability. Meanwhile, agent-based frameworks offer flexibility but often lack seamless integration across diverse environments. This paper envisions the future of LLM applications and proposes a three-layer decoupled architecture grounded in software engineering principles such as layered system design, service-oriented architectures, and hardware-software co-design. This architecture separates application logic, communication protocols, and hardware execution, enhancing modularity, efficiency, and cross-platform compatibility. Beyond architecture, we highlight key security and privacy challenges for safe, scalable AI deployment and outline research directions in software and security engineering. This vision aims to foster open, secure, and interoperable LLM ecosystems, guiding future advancements in AI applications.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04596"
    },
    {
        "title": "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making",
        "authors": "Yitong Luo, \n      \n      Hou Hei Lam, \n      \n      Ziang Chen, \n      \n      Zhenliang Zhang, \n      \n      Xue Feng",
        "summary": "Despite recent advances in artificial intelligence (AI), it poses challenges to ensure personalized decision-making in tasks that are not considered in training datasets. To address this issue, we propose ValuePilot, a two-phase value-driven decision-making framework comprising a dataset generation toolkit DGT and a decision-making module DMM trained on the generated data. DGT is capable of generating scenarios based on value dimensions and closely mirroring real-world tasks, with automated filtering techniques and human curation to ensure the validity of the dataset. In the generated dataset, DMM learns to recognize the inherent values of scenarios, computes action feasibility and navigates the trade-offs between multiple value dimensions to make personalized decisions. Extensive experiments demonstrate that, given human value preferences, our DMM most closely aligns with human decisions, outperforming Claude-3.5-Sonnet, Gemini-2-flash, Llama-3.1-405b and GPT-4o. This research is a preliminary exploration of value-driven decision-making. We hope it will stimulate interest in value-driven decision-making and personalized decision-making within the community.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04569"
    },
    {
        "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association",
        "authors": "Xiang Zhang, \n      \n      Zhou Li, \n      \n      Kai Wan, \n      \n      Hua Sun, \n      \n      Mingyue Ji, \n      \n      Giuseppe Caire",
        "summary": "Secure aggregation is motivated by federated learning (FL) where a cloud server aims to compute an averaged model (i.e., weights of deep neural networks) of the locally-trained models of numerous clients, while adhering to data security requirements. Hierarchical secure aggregation (HSA) extends this concept to a three-layer network, where clustered users communicate with the server through an intermediate layer of relays. In HSA, beyond conventional server security, relay security is also enforced to ensure that the relays remain oblivious to the users' inputs (an abstraction of the local models in FL). Existing study on HSA assumes that each user is associated with only one relay, limiting opportunities for coding across inter-cluster users to achieve efficient communication and key generation. In this paper, we consider HSA with a cyclic association pattern where each user is connected to $B$ consecutive relays in a wrap-around manner. We propose an efficient aggregation scheme which includes a message design for the inputs inspired by gradient coding-a well-known technique for efficient communication in distributed computing-along with a highly nontrivial security key design. We also derive novel converse bounds on the minimum achievable communication and key rates using information-theoretic arguments.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04564"
    },
    {
        "title": "Compositional Causal Reasoning Evaluation in Language Models",
        "authors": "Jacqueline R. M. A. Maasch, \n      \n      Alihan H\u00fcy\u00fck, \n      \n      Xinnuo Xu, \n      \n      Aditya V. Nori, \n      \n      Javier Gonzalez",
        "summary": "Causal reasoning and compositional reasoning are two core aspirations in generative AI. Measuring the extent of these behaviors requires principled evaluation methods. We explore a unified perspective that considers both behaviors simultaneously, termed compositional causal reasoning (CCR): the ability to infer how causal measures compose and, equivalently, how causal quantities propagate through graphs. We instantiate a framework for the systematic evaluation of CCR for the average treatment effect and the probability of necessity and sufficiency. As proof of concept, we demonstrate the design of CCR tasks for language models in the LLama, Phi, and GPT families. On a math word problem, our framework revealed a range of taxonomically distinct error patterns. Additionally, CCR errors increased with the complexity of causal paths for all models except o1.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04556"
    },
    {
        "title": "Benchmarking Reasoning Robustness in Large Language Models",
        "authors": "Tong Yu, \n      \n      Yongcheng Jing, \n      \n      Xikun Zhang, \n      \n      Wentao Jiang, \n      \n      Wenjie Wu, \n      \n      Yingjie Wang, \n      \n      Wenbin Hu, \n      \n      Bo Du, \n      \n      Dacheng Tao",
        "summary": "Despite the recent success of large language models (LLMs) in reasoning such as DeepSeek, we for the first time identify a key dilemma in reasoning robustness and generalization: significant performance degradation on novel or incomplete data, suggesting a reliance on memorized patterns rather than systematic reasoning. Our closer examination reveals four key unique limitations underlying this issue:(1) Positional bias--models favor earlier queries in multi-query inputs but answering the wrong one in the latter (e.g., GPT-4o's accuracy drops from 75.8 percent to 72.8 percent); (2) Instruction sensitivity--performance declines by 5.0 to 7.5 percent in the Qwen2.5 Series and by 5.0 percent in DeepSeek-V3 with auxiliary guidance; (3) Numerical fragility--value substitution sharply reduces accuracy (e.g., GPT-4o drops from 97.5 percent to 82.5 percent, GPT-o1-mini drops from 97.5 percent to 92.5 percent); and (4) Memory dependence--models resort to guesswork when missing critical data. These findings further highlight the reliance on heuristic recall over rigorous logical inference, demonstrating challenges in reasoning robustness. To comprehensively investigate these robustness challenges, this paper introduces a novel benchmark, termed as Math-RoB, that exploits hallucinations triggered by missing information to expose reasoning gaps. This is achieved by an instruction-based approach to generate diverse datasets that closely resemble training distributions, facilitating a holistic robustness assessment and advancing the development of more robust reasoning frameworks. Bad character(s) in field Abstract.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04550"
    },
    {
        "title": "Keeping Yourself is Important in Downstream Tuning Multimodal Large Language Model",
        "authors": "Wenke Huang, \n      \n      Jian Liang, \n      \n      Xianda Guo, \n      \n      Yiyang Fang, \n      \n      Guancheng Wan, \n      \n      Xuankun Rong, \n      \n      Chi Wen, \n      \n      Zekun Shi, \n      \n      Qingyun Li, \n      \n      Didi Zhu, \n      \n      Yanbiao Ma, \n      \n      Ke Liang, \n      \n      Bin Yang, \n      \n      He Li, \n      \n      Jiawei Shao, \n      \n      Mang Ye, \n      \n      Bo Du",
        "summary": "Multi-modal Large Language Models (MLLMs) integrate visual and linguistic reasoning to address complex tasks such as image captioning and visual question answering. While MLLMs demonstrate remarkable versatility, MLLMs appears limited performance on special applications. But tuning MLLMs for downstream tasks encounters two key challenges: Task-Expert Specialization, where distribution shifts between pre-training and target datasets constrain target performance, and Open-World Stabilization, where catastrophic forgetting erases the model general knowledge. In this work, we systematically review recent advancements in MLLM tuning methodologies, classifying them into three paradigms: (I) Selective Tuning, (II) Additive Tuning, and (III) Reparameterization Tuning. Furthermore, we benchmark these tuning strategies across popular MLLM architectures and diverse downstream tasks to establish standardized evaluation analysis and systematic tuning principles. Finally, we highlight several open challenges in this domain and propose future research directions. To facilitate ongoing progress in this rapidly evolving field, we provide a public repository that continuously tracks developments: https://github.com/WenkeHuang/Awesome-MLLM-Tuning.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04543"
    },
    {
        "title": "SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning",
        "authors": "Chen Li, \n      \n      Yinyi Luo, \n      \n      Anudeep Bolimera, \n      \n      Marios Savvides",
        "summary": "Large Language Models (LLMs) excel in reasoning but remain constrained by their Chain-of-Thought (CoT) approach, which struggles with complex tasks requiring more nuanced topological reasoning. We introduce SOLAR, Scalable Optimization of Large-scale Architecture for Reasoning, a framework that dynamically optimizes various reasoning topologies to enhance accuracy and efficiency.\n  Our Topological Annotation Generation (TAG) system automates topological dataset creation and segmentation, improving post-training and evaluation. Additionally, we propose Topological-Scaling, a reward-driven framework that aligns training and inference scaling, equipping LLMs with adaptive, task-aware reasoning.\n  SOLAR achieves substantial gains on MATH and GSM8K: +5% accuracy with Topological Tuning, +9% with Topological Reward, and +10.02% with Hybrid Scaling. It also reduces response length by over 5% for complex problems, lowering inference latency.\n  To foster the reward system, we train a multi-task Topological Reward Model (M-TRM), which autonomously selects the best reasoning topology and answer in a single pass, eliminating the need for training and inference on multiple single-task TRMs (S-TRMs), thus reducing both training cost and inference latency. In addition, in terms of performance, M-TRM surpasses all S-TRMs, improving accuracy by +10% and rank correlation by +9%.\n  To the best of our knowledge, SOLAR sets a new benchmark for scalable, high-precision LLM reasoning while introducing an automated annotation process and a dynamic reasoning topology competition mechanism.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04530"
    },
    {
        "title": "Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market",
        "authors": "Songyuan Li, \n      \n      Jia Hu, \n      \n      Geyong Min, \n      \n      Haojun Huang, \n      \n      Jiwei Huang",
        "summary": "The convergence of edge computing and AI gives rise to Edge-AI, which enables the deployment of real-time AI applications and services at the network edge. One of the fundamental research issues in Edge-AI is edge inference acceleration, which aims to realize low-latency high-accuracy DNN inference services by leveraging the fine-grained offloading of partitioned inference tasks from end devices to edge servers. However, existing research has yet to adopt a practical Edge-AI market perspective, which would systematically explore the personalized inference needs of AI users (e.g., inference accuracy, latency, and task complexity), the revenue incentives for AI service providers that offer edge inference services, and multi-stakeholder governance within a market-oriented context. To bridge this gap, we propose an Auction-based Edge Inference Pricing Mechanism (AERIA) for revenue maximization to tackle the multi-dimensional optimization problem of DNN model partition, edge inference pricing, and resource allocation. We investigate the multi-exit device-edge synergistic inference scheme for on-demand DNN inference acceleration, and analyse the auction dynamics amongst the AI service providers, AI users and edge infrastructure provider. Owing to the strategic mechanism design via randomized consensus estimate and cost sharing techniques, the Edge-AI market attains several desirable properties, including competitiveness in revenue maximization, incentive compatibility, and envy-freeness, which are crucial to maintain the effectiveness, truthfulness, and fairness of our auction outcomes. The extensive simulation experiments based on four representative DNN inference workloads demonstrate that our AERIA mechanism significantly outperforms several state-of-the-art approaches in revenue maximization, demonstrating the efficacy of AERIA for on-demand DNN inference in the Edge-AI market.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04521"
    },
    {
        "title": "STX-Search: Explanation Search for Continuous Dynamic Spatio-Temporal Models",
        "authors": "Saif Anwar, \n      \n      Nathan Griffiths, \n      \n      Thomas Popham, \n      \n      Abhir Bhalerao",
        "summary": "Recent improvements in the expressive power of spatio-temporal models have led to performance gains in many real-world applications, such as traffic forecasting and social network modelling. However, understanding the predictions from a model is crucial to ensure reliability and trustworthiness, particularly for high-risk applications, such as healthcare and transport. Few existing methods are able to generate explanations for models trained on continuous-time dynamic graph data and, of these, the computational complexity and lack of suitable explanation objectives pose challenges. In this paper, we propose $\\textbf{S}$patio-$\\textbf{T}$emporal E$\\textbf{X}$planation $\\textbf{Search}$ (STX-Search), a novel method for generating instance-level explanations that is applicable to static and dynamic temporal graph structures. We introduce a novel search strategy and objective function, to find explanations that are highly faithful and interpretable. When compared with existing methods, STX-Search produces explanations of higher fidelity whilst optimising explanation size to maintain interpretability.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04509"
    },
    {
        "title": "Multi-modal Summarization in Model-Based Engineering: Automotive Software Development Case Study",
        "authors": "Nenad Petrovic, \n      \n      Yurui Zhang, \n      \n      Moaad Maaroufi, \n      \n      Kuo-Yi Chao, \n      \n      Lukasz Mazur, \n      \n      Fengjunjie Pan, \n      \n      Vahid Zolfaghari, \n      \n      Alois Knoll",
        "summary": "Multimodal summarization integrating information from diverse data modalities presents a promising solution to aid the understanding of information within various processes. However, the application and advantages of multimodal summarization have not received much attention in model-based engineering (MBE), where it has become a cornerstone in the design and development of complex systems, leveraging formal models to improve understanding, validation and automation throughout the engineering lifecycle. UML and EMF diagrams in model-based engineering contain a large amount of multimodal information and intricate relational data. Hence, our study explores the application of multimodal large language models within the domain of model-based engineering to evaluate their capacity for understanding and identifying relationships, features, and functionalities embedded in UML and EMF diagrams. We aim to demonstrate the transformative potential benefits and limitations of multimodal summarization in improving productivity and accuracy in MBE practices. The proposed approach is evaluated within the context of automotive software development, while many promising state-of-art models were taken into account.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04506"
    },
    {
        "title": "Interpretable Transformation and Analysis of Timelines through Learning via Surprisability",
        "authors": "Osnat Mokryn, \n      \n      Teddy Lazebnik, \n      \n      Hagit Ben Shoshan",
        "summary": "The analysis of high-dimensional timeline data and the identification of outliers and anomalies is critical across diverse domains, including sensor readings, biological and medical data, historical records, and global statistics. However, conventional analysis techniques often struggle with challenges such as high dimensionality, complex distributions, and sparsity. These limitations hinder the ability to extract meaningful insights from complex temporal datasets, making it difficult to identify trending features, outliers, and anomalies effectively. Inspired by surprisability -- a cognitive science concept describing how humans instinctively focus on unexpected deviations - we propose Learning via Surprisability (LvS), a novel approach for transforming high-dimensional timeline data. LvS quantifies and prioritizes anomalies in time-series data by formalizing deviations from expected behavior. LvS bridges cognitive theories of attention with computational methods, enabling the detection of anomalies and shifts in a way that preserves critical context, offering a new lens for interpreting complex datasets. We demonstrate the usefulness of LvS on three high-dimensional timeline use cases: a time series of sensor data, a global dataset of mortality causes over multiple years, and a textual corpus containing over two centuries of State of the Union Addresses by U.S. presidents. Our results show that the LvS transformation enables efficient and interpretable identification of outliers, anomalies, and the most variable features along the timeline.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04502"
    },
    {
        "title": "ReynoldsFlow: Exquisite Flow Estimation via Reynolds Transport Theorem",
        "authors": "Yu-Hsi Chen, \n      \n      Chin-Tien Wu",
        "summary": "Optical flow is a fundamental technique for motion estimation, widely applied in video stabilization, interpolation, and object tracking. Recent advancements in artificial intelligence (AI) have enabled deep learning models to leverage optical flow as an important feature for motion analysis. However, traditional optical flow methods rely on restrictive assumptions, such as brightness constancy and slow motion constraints, limiting their effectiveness in complex scenes. Deep learning-based approaches require extensive training on large domain-specific datasets, making them computationally demanding. Furthermore, optical flow is typically visualized in the HSV color space, which introduces nonlinear distortions when converted to RGB and is highly sensitive to noise, degrading motion representation accuracy. These limitations inherently constrain the performance of downstream models, potentially hindering object tracking and motion analysis tasks. To address these challenges, we propose Reynolds flow, a novel training-free flow estimation inspired by the Reynolds transport theorem, offering a principled approach to modeling complex motion dynamics. Beyond the conventional HSV-based visualization, denoted ReynoldsFlow, we introduce an alternative representation, ReynoldsFlow+, designed to improve flow visualization. We evaluate ReynoldsFlow and ReynoldsFlow+ across three video-based benchmarks: tiny object detection on UAVDB, infrared object detection on Anti-UAV, and pose estimation on GolfDB. Experimental results demonstrate that networks trained with ReynoldsFlow+ achieve state-of-the-art (SOTA) performance, exhibiting improved robustness and efficiency across all tasks.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04500"
    },
    {
        "title": "Generalized Interpolating Discrete Diffusion",
        "authors": "Dimitri von R\u00fctte, \n      \n      Janis Fluri, \n      \n      Yuhui Ding, \n      \n      Antonio Orvieto, \n      \n      Bernhard Sch\u00f6lkopf, \n      \n      Thomas Hofmann",
        "summary": "While state-of-the-art language models achieve impressive results through next-token prediction, they have inherent limitations such as the inability to revise already generated tokens. This has prompted exploration of alternative approaches such as discrete diffusion. However, masked diffusion, which has emerged as a popular choice due to its simplicity and effectiveness, reintroduces this inability to revise words. To overcome this, we generalize masked diffusion and derive the theoretical backbone of a family of general interpolating discrete diffusion (GIDD) processes offering greater flexibility in the design of the noising processes. Leveraging a novel diffusion ELBO, we achieve compute-matched state-of-the-art performance in diffusion language modeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining masking and uniform noise, leading to improved sample quality and unlocking the ability for the model to correct its own mistakes, an area where autoregressive models notoriously have struggled. Our code and models are open-source: https://github.com/dvruette/gidd/\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04482"
    },
    {
        "title": "ToolFuzz -- Automated Agent Tool Testing",
        "authors": "Ivan Milev, \n      \n      Mislav Balunovi\u0107, \n      \n      Maximilian Baader, \n      \n      Martin Vechev",
        "summary": "Large Language Model (LLM) Agents leverage the advanced reasoning capabilities of LLMs in real-world applications. To interface with an environment, these agents often rely on tools, such as web search or database APIs. As the agent provides the LLM with tool documentation along the user query, the completeness and correctness of this documentation is critical. However, tool documentation is often over-, under-, or ill-specified, impeding the agent's accuracy. Standard software testing approaches struggle to identify these errors as they are expressed in natural language. Thus, despite its importance, there currently exists no automated method to test the tool documentation for agents. To address this issue, we present ToolFuzz, the first method for automated testing of tool documentations. ToolFuzz is designed to discover two types of errors: (1) user queries leading to tool runtime errors and (2) user queries that lead to incorrect agent responses. ToolFuzz can generate a large and diverse set of natural inputs, effectively finding tool description errors at a low false positive rate. Further, we present two straightforward prompt-engineering approaches. We evaluate all three tool testing approaches on 32 common LangChain tools and 35 newly created custom tools and 2 novel benchmarks to further strengthen the assessment. We find that many publicly available tools suffer from underspecification. Specifically, we show that ToolFuzz identifies 20x more erroneous inputs compared to the prompt-engineering approaches, making it a key component for building reliable AI agents.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04479"
    },
    {
        "title": "DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models",
        "authors": "Yi Shen, \n      \n      Jian Zhang, \n      \n      Jieyun Huang, \n      \n      Shuming Shi, \n      \n      Wenjing Zhang, \n      \n      Jiangze Yan, \n      \n      Ning Wang, \n      \n      Kai Wang, \n      \n      Shiguo Lian",
        "summary": "Recent advancements in slow-thinking reasoning models have shown exceptional performance in complex reasoning tasks. However, these models often exhibit overthinking-generating redundant reasoning steps for simple problems, leading to excessive computational resource usage. While current mitigation strategies uniformly reduce reasoning tokens, they risk degrading performance on challenging tasks that require extended reasoning. This paper introduces Difficulty-Adaptive Slow-Thinking (DAST), a novel framework that enables models to autonomously adjust the length of Chain-of-Thought(CoT) based on problem difficulty. We first propose a Token Length Budget (TLB) metric to quantify difficulty, then leveraging length-aware reward shaping and length preference optimization to implement DAST. DAST penalizes overlong responses for simple tasks while incentivizing sufficient reasoning for complex problems. Experiments on diverse datasets and model scales demonstrate that DAST effectively mitigates overthinking (reducing token usage by over 30\\% on average) while preserving reasoning accuracy on complex problems.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04472"
    },
    {
        "title": "An artificially intelligent magnetic resonance spectroscopy quantification method: Comparison between QNet and LCModel on the cloud computing platform CloudBrain-MRS",
        "authors": "Meijin Lin, \n      \n      Lin Guo, \n      \n      Dicheng Chen, \n      \n      Jianshu Chen, \n      \n      Zhangren Tu, \n      \n      Xu Huang, \n      \n      Jianhua Wang, \n      \n      Ji Qi, \n      \n      Yuan Long, \n      \n      Zhiguo Huang, \n      \n      Di Guo, \n      \n      Xiaobo Qu, \n      \n      Haiwei Han",
        "summary": "Objctives: This work aimed to statistically compare the metabolite quantification of human brain magnetic resonance spectroscopy (MRS) between the deep learning method QNet and the classical method LCModel through an easy-to-use intelligent cloud computing platform CloudBrain-MRS. Materials and Methods: In this retrospective study, two 3 T MRI scanners Philips Ingenia and Achieva collected 61 and 46 in vivo 1H magnetic resonance (MR) spectra of healthy participants, respectively, from the brain region of pregenual anterior cingulate cortex from September to October 2021. The analyses of Bland-Altman, Pearson correlation and reasonability were performed to assess the degree of agreement, linear correlation and reasonability between the two quantification methods. Results: Fifteen healthy volunteers (12 females and 3 males, age range: 21-35 years, mean age/standard deviation = 27.4/3.9 years) were recruited. The analyses of Bland-Altman, Pearson correlation and reasonability showed high to good consistency and very strong to moderate correlation between the two methods for quantification of total N-acetylaspartate (tNAA), total choline (tCho), and inositol (Ins) (relative half interval of limits of agreement = 3.04%, 9.3%, and 18.5%, respectively; Pearson correlation coefficient r = 0.775, 0.927, and 0.469, respectively). In addition, quantification results of QNet are more likely to be closer to the previous reported average values than those of LCModel. Conclusion: There were high or good degrees of consistency between the quantification results of QNet and LCModel for tNAA, tCho, and Ins, and QNet generally has more reasonable quantification than LCModel.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04469"
    },
    {
        "title": "TPC: Cross-Temporal Prediction Connection for Vision-Language Model Hallucination Reduction",
        "authors": "Chao Wang, \n      \n      Weiwei Fu, \n      \n      Yang Zhou",
        "summary": "Vision-language models (VLMs) have achieved remarkable advancements, capitalizing on the impressive capabilities of large language models (LLMs) across diverse tasks. Despite this, a critical challenge known as hallucination occurs when models overconfidently describe objects or attributes absent from the image, a problem exacerbated by the tendency of VLMs to rely on linguistic priors. This limitation reduces model reliability in high-stakes applications. In this work, we have observed the characteristic of logits' continuity consistency enhancement and introduced a straightforward and efficient method, Cross-Temporal Prediction Connection (TPC), designed to enhance the semantic consistency of logits by connecting them temporally across timesteps. TPC amplifies information flow and improves coherence, effectively reducing hallucination. Extensive experiments show that TPC surpasses existing representatives, delivering superior performance in both accuracy and efficiency while maintaining robustness in open-ended text generation tasks.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04457"
    },
    {
        "title": "Privacy Preserving and Robust Aggregation for Cross-Silo Federated Learning in Non-IID Settings",
        "authors": "Marco Arazzi, \n      \n      Mert Cihangiroglu, \n      \n      Antonino Nocera",
        "summary": "Federated Averaging remains the most widely used aggregation strategy in federated learning due to its simplicity and scalability. However, its performance degrades significantly in non-IID data settings, where client distributions are highly imbalanced or skewed. Additionally, it relies on clients transmitting metadata, specifically the number of training samples, which introduces privacy risks and may conflict with regulatory frameworks like the European GDPR. In this paper, we propose a novel aggregation strategy that addresses these challenges by introducing class-aware gradient masking. Unlike traditional approaches, our method relies solely on gradient updates, eliminating the need for any additional client metadata, thereby enhancing privacy protection. Furthermore, our approach validates and dynamically weights client contributions based on class-specific importance, ensuring robustness against non-IID distributions, convergence prevention, and backdoor attacks. Extensive experiments on benchmark datasets demonstrate that our method not only outperforms FedAvg and other widely accepted aggregation strategies in non-IID settings but also preserves model integrity in adversarial scenarios. Our results establish the effectiveness of gradient masking as a practical and secure solution for federated learning.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04451"
    },
    {
        "title": "Activation Space Interventions Can Be Transferred Between Large Language Models",
        "authors": "Narmeen Oozeer, \n      \n      Dhruv Nathawani, \n      \n      Nirmalendu Prakash, \n      \n      Michael Lan, \n      \n      Abir Harrasse, \n      \n      Amirali Abdullah",
        "summary": "The study of representation universality in AI models reveals growing convergence across domains, modalities, and architectures. However, the practical applications of representation universality remain largely unexplored. We bridge this gap by demonstrating that safety interventions can be transferred between models through learned mappings of their shared activation spaces. We demonstrate this approach on two well-established AI safety tasks: backdoor removal and refusal of harmful prompts, showing successful transfer of steering vectors that alter the models' outputs in a predictable way. Additionally, we propose a new task, \\textit{corrupted capabilities}, where models are fine-tuned to embed knowledge tied to a backdoor. This tests their ability to separate useful skills from backdoors, reflecting real-world challenges. Extensive experiments across Llama, Qwen and Gemma model families show that our method enables using smaller models to efficiently align larger ones. Furthermore, we demonstrate that autoencoder mappings between base and fine-tuned models can serve as reliable ``lightweight safety switches\", allowing dynamic toggling between model behaviors.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04429"
    },
    {
        "title": "PDX: A Data Layout for Vector Similarity Search",
        "authors": "Leonardo Kuffo, \n      \n      Elena Krippner, \n      \n      Peter Boncz",
        "summary": "We propose Partition Dimensions Across (PDX), a data layout for vectors (e.g., embeddings) that, similar to PAX [6], stores multiple vectors in one block, using a vertical layout for the dimensions (Figure 1). PDX accelerates exact and approximate similarity search thanks to its dimension-by-dimension search strategy that operates on multiple-vectors-at-a-time in tight loops. It beats SIMD-optimized distance kernels on standard horizontal vector storage (avg 40% faster), only relying on scalar code that gets auto-vectorized. We combined the PDX layout with recent dimension-pruning algorithms ADSampling [19] and BSA [52] that accelerate approximate vector search. We found that these algorithms on the horizontal vector layout can lose to SIMD-optimized linear scans, even if they are SIMD-optimized. However, when used on PDX, their benefit is restored to 2-7x. We find that search on PDX is especially fast if a limited number of dimensions has to be scanned fully, which is what the dimension-pruning approaches do. We finally introduce PDX-BOND, an even more flexible dimension-pruning strategy, with good performance on exact search and reasonable performance on approximate search. Unlike previous pruning algorithms, it can work on vector data \"as-is\" without preprocessing; making it attractive for vector databases with frequent updates.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04422"
    },
    {
        "title": "From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative Design",
        "authors": "Felix Ocker, \n      \n      Stefan Menzel, \n      \n      Ahmed Sadik, \n      \n      Thiago Rios",
        "summary": "Creating digital models using Computer Aided Design (CAD) is a process that requires in-depth expertise. In industrial product development, this process typically involves entire teams of engineers, spanning requirements engineering, CAD itself, and quality assurance. We present an approach that mirrors this team structure with a Vision Language Model (VLM)-based Multi Agent System, with access to parametric CAD tooling and tool documentation. Combining agents for requirements engineering, CAD engineering, and vision-based quality assurance, a model is generated automatically from sketches and/ or textual descriptions. The resulting model can be refined collaboratively in an iterative validation loop with the user. Our approach has the potential to increase the effectiveness of design processes, both for industry experts and for hobbyists who create models for 3D printing. We demonstrate the potential of the architecture at the example of various design tasks and provide several ablations that show the benefits of the architecture's individual components.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04417"
    },
    {
        "title": "Learning Transformer-based World Models with Contrastive Predictive Coding",
        "authors": "Maxime Burchi, \n      \n      Radu Timofte",
        "summary": "The DreamerV3 algorithm recently obtained remarkable performance across diverse environment domains by learning an accurate world model based on Recurrent Neural Networks (RNNs). Following the success of model-based reinforcement learning algorithms and the rapid adoption of the Transformer architecture for its superior training efficiency and favorable scaling properties, recent works such as STORM have proposed replacing RNN-based world models with Transformer-based world models using masked self-attention. However, despite the improved training efficiency of these methods, their impact on performance remains limited compared to the Dreamer algorithm, struggling to learn competitive Transformer-based world models. In this work, we show that the next state prediction objective adopted in previous approaches is insufficient to fully exploit the representation capabilities of Transformers. We propose to extend world model predictions to longer time horizons by introducing TWISTER (Transformer-based World model wIth contraSTivE Representations), a world model using action-conditioned Contrastive Predictive Coding to learn high-level temporal feature representations and improve the agent performance. TWISTER achieves a human-normalized mean score of 162% on the Atari 100k benchmark, setting a new record among state-of-the-art methods that do not employ look-ahead search.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04416"
    },
    {
        "title": "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search",
        "authors": "Kou Misaki, \n      \n      Yuichi Inoue, \n      \n      Yuki Imajuku, \n      \n      So Kuroki, \n      \n      Taishi Nakamura, \n      \n      Takuya Akiba",
        "summary": "Recent advances demonstrate that increasing inference-time computation can significantly boost the reasoning capabilities of large language models (LLMs). Although repeated sampling (i.e., generating multiple candidate outputs) is a highly effective strategy, it does not leverage external feedback signals for refinement, which are often available in tasks like coding. In this work, we propose $\\textit{Adaptive Branching Monte Carlo Tree Search (AB-MCTS)}$, a novel inference-time framework that generalizes repeated sampling with principled multi-turn exploration and exploitation. At each node in the search tree, AB-MCTS dynamically decides whether to \"go wider\" by expanding new candidate responses or \"go deeper\" by revisiting existing ones based on external feedback signals. We evaluate our method on complex coding and engineering tasks using frontier models. Empirical results show that AB-MCTS consistently outperforms both repeated sampling and standard MCTS, underscoring the importance of combining the response diversity of LLMs with multi-turn solution refinement for effective inference-time scaling.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04412"
    },
    {
        "title": "Training-Free Graph Filtering via Multimodal Feature Refinement for Extremely Fast Multimodal Recommendation",
        "authors": "Yu-Seung Roh, \n      \n      Joo-Young Kim, \n      \n      Jin-Duk Park, \n      \n      Won-Yong Shin",
        "summary": "Multimodal recommender systems improve the performance of canonical recommender systems with no item features by utilizing diverse content types such as text, images, and videos, while alleviating inherent sparsity of user-item interactions and accelerating user engagement. However, current neural network-based models often incur significant computational overhead due to the complex training process required to learn and integrate information from multiple modalities. To overcome this limitation, we propose MultiModal-Graph Filtering (MM-GF), a training-free method based on the notion of graph filtering (GF) for efficient and accurate multimodal recommendations. Specifically, MM-GF first constructs multiple similarity graphs through nontrivial multimodal feature refinement such as robust scaling and vector shifting by addressing the heterogeneous characteristics across modalities. Then, MM-GF optimally fuses multimodal information using linear low-pass filters across different modalities. Extensive experiments on real-world benchmark datasets demonstrate that MM-GF not only improves recommendation accuracy by up to 13.35% compared to the best competitor but also dramatically reduces computational costs by achieving the runtime of less than 10 seconds.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04406"
    },
    {
        "title": "Speculative MoE: Communication Efficient Parallel MoE Inference with Speculative Token and Expert Pre-scheduling",
        "authors": "Yan Li, \n      \n      Pengfei Zheng, \n      \n      Shuang Chen, \n      \n      Zewei Xu, \n      \n      Yunfei Du, \n      \n      Zhengang Wang",
        "summary": "MoE (Mixture of Experts) prevails as a neural architecture that can scale modern transformer-based LLMs (Large Language Models) to unprecedented scales. Nevertheless, large MoEs' great demands of computing power, memory capacity and memory bandwidth make scalable serving a fundamental challenge and efficient parallel inference has become a requisite to attain adequate throughput under latency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference framework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP (Tensor Parallel) and DP (Data Parallelism). However, our analysis shows DeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is implemented with costly all-to-all collectives to route token activation. Our work aims to boost DeepSpeed-MoE by strategically reducing EP's communication overhead with a technique named Speculative MoE. Speculative MoE has two speculative parallelization schemes, speculative token shuffling and speculative expert grouping, which predict outstanding tokens' expert routing paths and pre-schedule tokens and experts across devices to losslessly trim EP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE into a prevailing MoE inference engine SGLang. Experiments show Speculative MoE can significantly boost state-of-the-art MoE inference frameworks on fast homogeneous and slow heterogeneous interconnects.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04398"
    },
    {
        "title": "AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management",
        "authors": "Junyuan Mao, \n      \n      Fanci Meng, \n      \n      Yifan Duan, \n      \n      Miao Yu, \n      \n      Xiaojun Jia, \n      \n      Junfeng Fang, \n      \n      Yuxuan Liang, \n      \n      Kun Wang, \n      \n      Qingsong Wen",
        "summary": "Large Language Model based multi-agent systems are revolutionizing autonomous communication and collaboration, yet they remain vulnerable to security threats like unauthorized access and data breaches. To address this, we introduce AgentSafe, a novel framework that enhances MAS security through hierarchical information management and memory protection. AgentSafe classifies information by security levels, restricting sensitive data access to authorized agents. AgentSafe incorporates two components: ThreatSieve, which secures communication by verifying information authority and preventing impersonation, and HierarCache, an adaptive memory management system that defends against unauthorized access and malicious poisoning, representing the first systematic defense for agent memory. Experiments across various LLMs show that AgentSafe significantly boosts system resilience, achieving defense success rates above 80% under adversarial conditions. Additionally, AgentSafe demonstrates scalability, maintaining robust performance as agent numbers and information complexity grow. Results underscore effectiveness of AgentSafe in securing MAS and its potential for real-world application.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04392"
    },
    {
        "title": "Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks",
        "authors": "Zhilin Wang, \n      \n      Jiaqi Zeng, \n      \n      Olivier Delalleau, \n      \n      Daniel Egert, \n      \n      Ellie Evans, \n      \n      Hoo-Chang Shin, \n      \n      Felipe Soares, \n      \n      Yi Dong, \n      \n      Oleksii Kuchaiev",
        "summary": "Inference-Time Scaling has been critical to the success of recent models such as OpenAI o1 and DeepSeek R1. However, many techniques used to train models for inference-time scaling require tasks to have answers that can be verified, limiting their application to domains such as math, coding and logical reasoning. We take inspiration from how humans make first attempts, ask for detailed feedback from others and make improvements based on such feedback across a wide spectrum of open-ended endeavors. To this end, we collect data for and train dedicated Feedback and Edit Models that are capable of performing inference-time scaling for open-ended general-domain tasks. In our setup, one model generates an initial response, which are given feedback by a second model, that are then used by a third model to edit the response. We show that performance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo can be boosted by scaling the number of initial response drafts, effective feedback and edited responses. When scaled optimally, our setup based on 70B models from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7 as of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and DeepSeek R1 with 92.3.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04378"
    },
    {
        "title": "Causally Reliable Concept Bottleneck Models",
        "authors": "Giovanni De Felice, \n      \n      Arianna Casanova Flores, \n      \n      Francesco De Santis, \n      \n      Silvia Santini, \n      \n      Johannes Schneider, \n      \n      Pietro Barbiero, \n      \n      Alberto Termine",
        "summary": "Concept-based models are an emerging paradigm in deep learning that constrains the inference process to operate through human-interpretable concepts, facilitating explainability and human interaction. However, these architectures, on par with popular opaque neural models, fail to account for the true causal mechanisms underlying the target phenomena represented in the data. This hampers their ability to support causal reasoning tasks, limits out-of-distribution generalization, and hinders the implementation of fairness constraints. To overcome these issues, we propose \\emph{Causally reliable Concept Bottleneck Models} (C$^2$BMs), a class of concept-based architectures that enforce reasoning through a bottleneck of concepts structured according to a model of the real-world causal mechanisms. We also introduce a pipeline to automatically learn this structure from observational data and \\emph{unstructured} background knowledge (e.g., scientific literature). Experimental evidence suggest that C$^2$BM are more interpretable, causally reliable, and improve responsiveness to interventions w.r.t. standard opaque and concept-based models, while maintaining their accuracy.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04363"
    },
    {
        "title": "A Generalist Cross-Domain Molecular Learning Framework for Structure-Based Drug Discovery",
        "authors": "Yiheng Zhu, \n      \n      Mingyang Li, \n      \n      Junlong Liu, \n      \n      Kun Fu, \n      \n      Jiansheng Wu, \n      \n      Qiuyi Li, \n      \n      Mingze Yin, \n      \n      Jieping Ye, \n      \n      Jian Wu, \n      \n      Zheng Wang",
        "summary": "Structure-based drug discovery (SBDD) is a systematic scientific process that develops new drugs by leveraging the detailed physical structure of the target protein. Recent advancements in pre-trained models for biomolecules have demonstrated remarkable success across various biochemical applications, including drug discovery and protein engineering. However, in most approaches, the pre-trained models primarily focus on the characteristics of either small molecules or proteins, without delving into their binding interactions which are essential cross-domain relationships pivotal to SBDD. To fill this gap, we propose a general-purpose foundation model named BIT (an abbreviation for Biomolecular Interaction Transformer), which is capable of encoding a range of biochemical entities, including small molecules, proteins, and protein-ligand complexes, as well as various data formats, encompassing both 2D and 3D structures. Specifically, we introduce Mixture-of-Domain-Experts (MoDE) to handle the biomolecules from diverse biochemical domains and Mixture-of-Structure-Experts (MoSE) to capture positional dependencies in the molecular structures. The proposed mixture-of-experts approach enables BIT to achieve both deep fusion and domain-specific encoding, effectively capturing fine-grained molecular interactions within protein-ligand complexes. Then, we perform cross-domain pre-training on the shared Transformer backbone via several unified self-supervised denoising tasks. Experimental results on various benchmarks demonstrate that BIT achieves exceptional performance in downstream tasks, including binding affinity prediction, structure-based virtual screening, and molecular property prediction.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04362"
    },
    {
        "title": "scDD: Latent Codes Based scRNA-seq Dataset Distillation with Foundation Model Knowledge",
        "authors": "Zhen Yu, \n      \n      Jianan Han, \n      \n      Yang Liu, \n      \n      Qingchao Chen",
        "summary": "Single-cell RNA sequencing (scRNA-seq) technology has profiled hundreds of millions of human cells across organs, diseases, development and perturbations to date. However, the high-dimensional sparsity, batch effect noise, category imbalance, and ever-increasing data scale of the original sequencing data pose significant challenges for multi-center knowledge transfer, data fusion, and cross-validation between scRNA-seq datasets. To address these barriers, (1) we first propose a latent codes-based scRNA-seq dataset distillation framework named scDD, which transfers and distills foundation model knowledge and original dataset information into a compact latent space and generates synthetic scRNA-seq dataset by a generator to replace the original dataset. Then, (2) we propose a single-step conditional diffusion generator named SCDG, which perform single-step gradient back-propagation to help scDD optimize distillation quality and avoid gradient decay caused by multi-step back-propagation. Meanwhile, SCDG ensures the scRNA-seq data characteristics and inter-class discriminability of the synthetic dataset through flexible conditional control and generation quality assurance. Finally, we propose a comprehensive benchmark to evaluate the performance of scRNA-seq dataset distillation in different data analysis tasks. It is validated that our proposed method can achieve 7.61% absolute and 15.70% relative improvement over previous state-of-the-art methods on average task.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04357"
    },
    {
        "title": "Talking Back -- human input and explanations to interactive AI systems",
        "authors": "Alan Dix, \n      \n      Tommaso Turchi, \n      \n      Ben Wilson, \n      \n      Anna Monreale, \n      \n      Matt Roach",
        "summary": "While XAI focuses on providing AI explanations to humans, can the reverse - humans explaining their judgments to AI - foster richer, synergistic human-AI systems? This paper explores various forms of human inputs to AI and examines how human explanations can guide machine learning models toward automated judgments and explanations that align more closely with human concepts.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04343"
    },
    {
        "title": "Energy Consumption of Robotic Arm with the Local Reduction Method",
        "authors": "Halima Ibrahim Kure, \n      \n      Jishna Retnakumari, \n      \n      Lucian Nita, \n      \n      Saeed Sharif, \n      \n      Hamed Balogun, \n      \n      Augustine O. Nwajana",
        "summary": "Energy consumption in robotic arms is a significant concern in industrial automation due to rising operational costs and environmental impact. This study investigates the use of a local reduction method to optimize energy efficiency in robotic systems without compromising performance. The approach refines movement parameters, minimizing energy use while maintaining precision and operational reliability. A three-joint robotic arm model was tested using simulation over a 30-second period for various tasks, including pick-and-place and trajectory-following operations. The results revealed that the local reduction method reduced energy consumption by up to 25% compared to traditional techniques such as Model Predictive Control (MPC) and Genetic Algorithms (GA). Unlike MPC, which requires significant computational resources, and GA, which has slow convergence rates, the local reduction method demonstrated superior adaptability and computational efficiency in real-time applications. The study highlights the scalability and simplicity of the local reduction approach, making it an attractive option for industries seeking sustainable and cost-effective solutions. Additionally, this method can integrate seamlessly with emerging technologies like Artificial Intelligence (AI), further enhancing its application in dynamic and complex environments. This research underscores the potential of the local reduction method as a practical tool for optimizing robotic arm operations, reducing energy demands, and contributing to sustainability in industrial automation. Future work will focus on extending the approach to real-world scenarios and incorporating AI-driven adjustments for more dynamic adaptability.\n        \u25b3 Less",
        "pdf_link": "https://arxiv.org/pdf/2503.04340"
    },
    {
        "title": "[BOEK][B] Artificial intelligence",
        "pdf_link": "https://books.google.com/books?hl=nl&lr=&id=9y2jBQAAQBAJ&oi=fnd&pg=PP1&dq=artificial+intelligence&ots=uQVu_p5XuB&sig=6SZQw0Ajsbpi7Brc8NH1FUPb1IQ",
        "summary": "Artificial Intelligence provides information pertinent to the fundamental aspects of artificial \nintelligence. This book presents the basic mathematical and computational approaches to \u2026",
        "authors": "EB Hunt - 2014 - books.google.com"
    },
    {
        "title": "Artificial intelligence in medicine",
        "pdf_link": "https://link.springer.com/content/pdf/10.1007/978-3-319-19551-3.pdf",
        "summary": "The European Society for Artificial Intelligence in Medicine (AIME) was established in 1986 \nfollowing a very successful workshop held in Pavia, Italy, the year before. The principal aims \u2026",
        "authors": "J Holmes, L Sacchi, R Bellazzi\u00a0- Ann R Coll Surg Engl, 2004 - Springer"
    },
    {
        "title": "[HTML][HTML] Quo vadis artificial intelligence?",
        "pdf_link": "https://link.springer.com/article/10.1007/s44163-022-00022-8",
        "summary": "\u2026 intelligence into machines, which constitutes the original motivation of Artificial Intelligence \n(AI). \u2026 There are many definitions of artificial intelligence. In the Turing test, AI is defined as the \u2026",
        "authors": "Y Jiang, X Li, H Luo, S Yin, O Kaynak\u00a0- Discover Artificial Intelligence, 2022 - Springer"
    },
    {
        "title": "What is artificial intelligence?",
        "pdf_link": "https://link.springer.com/content/pdf/10.1007/978-94-009-1900-6_1?pdf=chapter%20toc",
        "summary": "One of the fascinating aspects of the field of artificial intelligence (AI) is that the precise nature \nof its subject matter turns out to be surprisingly difficult to define. The problem, of course, \u2026",
        "authors": "JH Fetzer\u00a0- Artificial intelligence: Its scope and limits, 1990 - Springer"
    },
    {
        "title": "[BOEK][B] Artificial intelligence",
        "pdf_link": "https://dl.acm.org/doi/abs/10.5555/129914",
        "summary": "\u2026 \u0130nan RAksoy BSalman O(2023)Estimation performance of the novel hybrid estimator based on \nmachine learning and extended Kalman filter proposed for speed-sensorless direct torque control\u00a0\u2026",
        "authors": "PH Winston - 1992 - dl.acm.org"
    },
    {
        "title": "Artificial intelligence in medicine",
        "pdf_link": "https://www.sciencedirect.com/science/article/pii/S002604951730015X",
        "summary": "\u2026 artificial intelligence\u201d (AI) in 1955, defining it as \u201cthe science and engineering of making \nintelligent \u2026 at a Dartmouth College conference on artificial intelligence. The conference gave birth \u2026",
        "authors": "P Hamet, J Tremblay\u00a0- metabolism, 2017 - Elsevier"
    },
    {
        "title": "[BOEK][B] Artificial intelligence",
        "pdf_link": "https://dl.acm.org/doi/abs/10.5555/30424",
        "summary": "\u2026 Artificial intelligence (AI) is the Science and Engineering domain concerned with the \ntheory and practice of developing systems that exhibit the characteristics we associate with\u00a0\u2026",
        "authors": "PH Winston - 1984 - dl.acm.org"
    },
    {
        "title": "Causability and explainability of artificial intelligence in medicine",
        "pdf_link": "https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1312",
        "summary": "Explainable artificial intelligence (AI) is attracting much interest in medicine. Technically, the \nproblem of explainability is as old as AI itself and classic AI represented comprehensible \u2026",
        "authors": "A Holzinger, G Langs, H Denk\u2026\u00a0- \u2026\u00a0Reviews: Data Mining\u00a0\u2026, 2019 - Wiley Online Library"
    },
    {
        "title": "[BOEK][B] Artificial intelligence",
        "pdf_link": "https://books.google.com/books?hl=nl&lr=&id=_ixmRlL9jcIC&oi=fnd&pg=PP1&dq=artificial+intelligence&ots=JRNE-UpASV&sig=W4AqT_KxNvZcIJepW0BYz9tuF1c",
        "summary": "Artificial Intelligence is the study of how to build or program computers to enable them to do \nwhat minds can do. This volume discusses the ways in which computational ideas and \u2026",
        "authors": "MA Boden - 1996 - books.google.com"
    },
    {
        "title": "[PDF][PDF] What is artificial intelligence",
        "pdf_link": "https://trilliumdynamix.com/jmc/whatisai.pdf",
        "summary": "\u2026 This article for the layman answers basic questions about artificial intelligence. The \nopinions expressed here are not all consensus opinion among researchers in AI. \u2026 We\u00a0\u2026",
        "authors": "J McCarthy - 2007 - trilliumdynamix.com"
    }
]
